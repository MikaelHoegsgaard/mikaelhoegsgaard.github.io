---
layout: default
---



```{r}
library(kableExtra)
options(knitr.table.format = "latex")
```

`r text_spec("Help", color = "red")`

`r text_spec("Help Help", background = "#D05A6E", color = "white", bold = T)`

`r text_spec("Hello", font_size = 20)`

`r text_spec("World", angle = 180)`

I am a PhD student in the Foundations of Machine Learning Group at Aarhus University, led by Kasper Green Larsen, whom I am also grateful to have as my advisor.
Before starting my PhD, I received a Bachelor's degree from the Mathematics Department at Aarhus University and a Master's degree in Statistics from the Statistics Department at Aarhus University.
My primary research interest is learning theory.


# Publications

### 2025

Understanding Aggregations of Proper Learners in Multiclass Classification\
Co-Authors: Julian Asilis, Grigoris Velegkas\
Conference: ALT 2025

Efficient Optimal PAC Learning\
Co-Authors: \
Conference: ALT 2025

### 2024

Majority-of-Three: The Simplest Optimal Learner?\
Co-Authors: Ishaq Aden-Ali, Kasper Green Larsen, Nikita Zhivotovskiy\
Conference: COLT 2024

Optimal Parallelization of Boosting\
Co-Authors: Arthur da Cunha, Kasper Green Larsen\
Conference: NeurIPS 2024

The Many Faces of Optimal Weak-to-Strong Learning\
Co-Authors: Kasper Green Larsen, Markus Engelund Mathiasen\
Conference: NeurIPS 2024

Sparse Dimensionality Reduction Revisited\
Co-Authors: Lior Kamma, Kasper Green Larsen, Jelani Nelson, Chris Schwiegelshohn\
Conference: ICML 2024


### 2023
The Fast Johnson-Lindenstrauss Transform Is Even Faster\
Co-Authors: Ora Nova Fandina, Kasper Green Larsen\
Conference: ICML 2023

AdaBoost is not an Optimal Weak to Strong Learner\
Co-Authors: Kasper Green Larsen, Martin Ritzert\
Conference: ICML 2023

Barriers for Faster Dimensionality Reduction\
Co-Authors: Ora Nova Fandina, Kasper Green Larsen\
Conference: STACS 2023

Optimally Interpolating between Ex-Ante Fairness and Welfare\
Co-Authors: Mikael HÃ¸gsgaard, Panagiotis Karras, Wenyu Ma, Nidhi Rathi, Chris Schwiegelshohn


