---
layout: default
---
I am a PhD student in the Foundations of Machine Learning Group at Aarhus University, led by [Kasper Green Larsen](https://cs.au.dk/~larsen/) whom I am also grateful to have as my advisor.
Before starting my PhD, I received a Bachelor's degree from the Mathematics Department at Aarhus University and a Master's degree in Statistics from the Statistics Department at Aarhus University.
My primary research interest is learning theory.



# Publications
Work by my Brilliant co-authors and me. I am thankful for their insights and collaboration, which have helped me grow.

### 2025

Understanding Aggregations of Proper Learners in Multiclass Classification\
Co-Authors: Julian Asilis, Grigoris Velegkas\
Conference: <span style="color:#267CB9; background-color:#267CB9">A</span><span style="color:white; background-color:#267CB9">ALT 2025</span><span style="color:#267CB9; background-color:#267CB9">A</span>

Efficient Optimal PAC Learning\
Co-Authors: \
Conference: <span style="color:#267CB9; background-color:#267CB9">A</span><span style="color:white; background-color:#267CB9">ALT 2025</span><span style="color:#267CB9; background-color:#267CB9">A</span>


### 2024



<span style="color:#267CB9; background-color:#267CB9">A</span><span style="color:white; background-color:#267CB9">NeurIPS 2024</span><span style="color:#267CB9; background-color:#267CB9">A</span>


<span style="color:#267CB9; background-color:#267CB9">A</span><span style="color:white; background-color:#267CB9">ICML 2023</span><span style="color:#267CB9; background-color:#267CB9">A</span>

<span style="color:#267CB9; background-color:#267CB9">A</span><span style="color:white; background-color:#267CB9">ICML 2023</span><span style="color:#267CB9; background-color:#267CB9">A</span>

<span style="color:#267CB9; background-color:#267CB9">A</span><span style="color:white; background-color:#267CB9">STACS 2023</span><span style="color:#267CB9; background-color:#267CB9">A</span>
Majority-of-Three: The Simplest Optimal Learner?\
Co-Authors: Ishaq Aden-Ali, Kasper Green Larsen, Nikita Zhivotovskiy\
Conference: 
<span style="color:#267CB9; background-color:#267CB9">A</span><span style="color:white; background-color:#267CB9">COLT 2024</span><span style="color:#267CB9; background-color:#267CB9">A</span>

Optimal Parallelization of Boosting\
Co-Authors: Arthur da Cunha, Kasper Green Larsen\
Conference:<span style="color:#267CB9; background-color:#267CB9">A</span><span style="color:white; background-color:#267CB9">NeurIPS 2024</span><span style="color:#267CB9; background-color:#267CB9">A</span>

The Many Faces of Optimal Weak-to-Strong Learning\
Co-Authors: Kasper Green Larsen, Markus Engelund Mathiasen\
Conference:<span style="color:#267CB9; background-color:#267CB9">A</span><span style="color:white; background-color:#267CB9">NeurIPS 2024</span><span style="color:#267CB9; background-color:#267CB9">A</span>

Sparse Dimensionality Reduction Revisited\
Co-Authors: Lior Kamma, Kasper Green Larsen, Jelani Nelson, Chris Schwiegelshohn\
Conference: <span style="color:#267CB9; background-color:#267CB9">A</span><span style="color:white; background-color:#267CB9">ICML 2024</span><span style="color:#267CB9; background-color:#267CB9">A</span>


### 2023
The Fast Johnson-Lindenstrauss Transform Is Even Faster\
Co-Authors: Ora Nova Fandina, Kasper Green Larsen\
Conference: ICML 2023

AdaBoost is not an Optimal Weak to Strong Learner\
Co-Authors: Kasper Green Larsen, Martin Ritzert\
Conference: ICML 2023

Barriers for Faster Dimensionality Reduction\
Co-Authors: Ora Nova Fandina, Kasper Green Larsen\
Conference: STACS 2023

Optimally Interpolating between Ex-Ante Fairness and Welfare\
Co-Authors: Mikael HÃ¸gsgaard, Panagiotis Karras, Wenyu Ma, Nidhi Rathi, Chris Schwiegelshohn


