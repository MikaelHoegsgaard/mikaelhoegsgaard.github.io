---
layout: default
---
<img src="Untitled.png" align="right" width="200px"/>
# About

I am a PhD student in the Foundations of Machine Learning Group at Aarhus University, led by [Kasper Green Larsen](https://cs.au.dk/~larsen/) whom I am also grateful to have as my advisor. Before starting my PhD, I received a Bachelor's degree from the Mathematics Department at Aarhus University and a Master's degree in Statistics from the Statistics Department at Aarhus University. My primary research interest is learning theory.
[<span style="color:#2d75d7; background-color:white"><b>My PhD study is set to end at August 2025, and I am currently seeking either a PostDoc position or a full-time role. Any help or advice will be greatly appreciated!</b></span>](https://www.linkedin.com/in/mikael-m%C3%B8ller-h%C3%B8gsgaard-6b1024269/)

<!-- #### My PhD study is set to end at August 2025, and I am currently seeking either a PostDoc position or a full-time role. Any help or advice will be greatly appreciated! -->


# Publications
Work by my Brilliant co-authors and me. I am thankful for their insights and collaboration, which have helped me grow.

### 2025

[Improved Margin Generalization Bounds for Voting Classifiers](https://cs.au.dk/~larsen/papers/MarginBoundVoting.pdf)\
Co-Authors: Kasper Green Larsen\
Manuscript: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">ARXIV</span><span style="color:#267CB9; background-color:#267CB9">l</span>

[On Agnostic PAC Learning in the Small Error Regime](https://arxiv.org/abs/2502.09496)\
Co-Authors: Julian Asilis, Grigoris Velegkas\
Manuscript: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">ARXIV</span><span style="color:#267CB9; background-color:#267CB9">l</span>

[Understanding Aggregations of Proper Learners in Multiclass Classification](https://arxiv.org/abs/2410.22749)\
Co-Authors: Julian Asilis, Grigoris Velegkas\
Conference: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">ALT 2025</span><span style="color:#267CB9; background-color:#267CB9">l</span>

[Efficient Optimal PAC Learning](https://arxiv.org/abs/2502.03620)\
Co-Authors: \
Conference: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">ALT 2025</span><span style="color:#267CB9; background-color:#267CB9">l</span>


### 2024

[Majority-of-Three: The Simplest Optimal Learner?](https://arxiv.org/abs/2403.08831)\
Co-Authors: Ishaq Aden-Ali, Kasper Green Larsen, Nikita Zhivotovskiy\
Conference: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">COLT 2024</span><span style="color:#267CB9; background-color:#267CB9">l</span>

[Optimal Parallelization of Boosting](https://arxiv.org/abs/2408.16653)\
Co-Authors: Arthur da Cunha, Kasper Green Larsen\
Conference: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">NeurIPS 2024</span><span style="color:#267CB9; background-color:#267CB9">l</span> <span style="color:#2461b4; background-color:white"><b> - Oral top 0.39% of submissions</b></span>

[The Many Faces of Optimal Weak-to-Strong Learning](https://arxiv.org/abs/2408.17148)\
Co-Authors: Kasper Green Larsen, Markus Engelund Mathiasen\
Conference: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">NeurIPS 2024</span><span style="color:#267CB9; background-color:#267CB9">l</span>

[Sparse Dimensionality Reduction Revisited](https://arxiv.org/abs/2302.06165)\
Co-Authors: Lior Kamma, Kasper Green Larsen, Jelani Nelson, Chris Schwiegelshohn\
Conference: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">ICML 2024</span><span style="color:#267CB9; background-color:#267CB9">l</span>


### 2023
[The Fast Johnson-Lindenstrauss Transform Is Even Faster](https://arxiv.org/abs/2204.01800)\
Co-Authors: Ora Nova Fandina, Kasper Green Larsen\
Conference: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">ICML 2023</span><span style="color:#267CB9; background-color:#267CB9">l</span>

[AdaBoost is not an Optimal Weak to Strong Learner](https://arxiv.org/abs/2301.11571)\
Co-Authors: Kasper Green Larsen, Martin Ritzert\
Conference: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">ICML 2023 </span><span style="color:#267CB9; background-color:#267CB9">l</span>
<span style="color:#2461b4; background-color:white"><b> - Oral top 2.37% of submissions</b></span>

[Barriers for Faster Dimensionality Reduction](https://arxiv.org/abs/2207.03304)\
Co-Authors: Ora Nova Fandina, Kasper Green Larsen\
Conference: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">STACS 2023</span><span style="color:#267CB9; background-color:#267CB9">l</span>

[Optimally Interpolating between Ex-Ante Fairness and Welfare](https://arxiv.org/abs/2302.03071)\
Co-Authors: Panagiotis Karras, Wenyu Ma, Nidhi Rathi, Chris Schwiegelshohn\
Manuscript: <span style="color:#267CB9; background-color:#267CB9">l</span><span style="color:white; background-color:#267CB9">ARXIV</span><span style="color:#267CB9; background-color:#267CB9">l</span>


